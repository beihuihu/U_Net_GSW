{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Author: Ankit Kariryaa, University of Bremen\n",
    "  \n",
    "  Modified by Xuehui Pi and Qiuqi Luo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 10:04:07.404796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np               # numerical array manipulation\n",
    "import pandas as pd\n",
    "import geopandas as gps\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from PIL import Image\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.geometry import mapping, shape\n",
    "import fiona\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import rasterio.mask\n",
    "import affine\n",
    "\n",
    "from core.UNet import UNet\n",
    "from core.losses import tversky, accuracy, dice_loss, IoU, recall, precision,F1_score\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.frame_info import FrameInfo\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.visualize import display_images\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 10:04:09.369717: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 10:04:09.371643: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-02-28 10:04:09.372607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-02-28 10:04:09.397570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.53GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-02-28 10:04:09.397598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-02-28 10:04:09.399720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-02-28 10:04:09.399827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-02-28 10:04:09.400704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-02-28 10:04:09.400985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-02-28 10:04:09.403068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-02-28 10:04:09.403595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-02-28 10:04:09.403718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-02-28 10:04:09.404044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-02-28 10:04:09.404073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-02-28 10:04:09.820585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-02-28 10:04:09.820613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-02-28 10:04:09.820618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-02-28 10:04:09.821221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13188 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:17:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto(\n",
    "    #device_count={\"CPU\": 64},\n",
    "    allow_soft_placement=True, \n",
    "    log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data related variables used in the notebook \n",
    "\n",
    "# For reading the GSW and annotated images generated in the step - 1\n",
    "\n",
    "base_dir = r'/home/nkd/hbh'\n",
    "image_type = '.png'\n",
    "GSW_fn = 'occurrence'\n",
    "annotation_fn = 'annotation'\n",
    "\n",
    "# For testing, images are divided into sequential patches \n",
    "patch_generation_stratergy = 'random'\n",
    "patch_size = (512,512,2) ## Height * Width * (Input or Output) channelsï¼š[GSW, ANNOTATION]\n",
    "BATCH_SIZE = 16 # Model is evaluated in batches; See https://keras.io/models/model/\n",
    "\n",
    "# # When stratergy == sequential\n",
    "step_size = (512,512)\n",
    "\n",
    "input_shape = (512,512,1)\n",
    "input_image_channel = [0]\n",
    "input_label_channel = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3446618/2374220410.py:3: enable_mixed_precision_graph_rewrite (from tensorflow.python.training.experimental.mixed_precision) is deprecated and will be removed after 2020-11-30.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision. There is a guide at https://www.tensorflow.org/guide/mixed_precision. Alternatively, `tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite` can be used, but this is not recommended for TF2 code.\n",
      "WARNING:tensorflow:You already have existing Sessions that do not use mixed precision. enable_mixed_precision_graph_rewrite() will not affect these Sessions.\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 10:04:09.903484: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-02-28 10:04:09.903897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.53GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-02-28 10:04:09.903937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-02-28 10:04:09.904013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-02-28 10:04:09.904025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-02-28 10:04:09.904036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-02-28 10:04:09.904048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-02-28 10:04:09.904059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-02-28 10:04:09.904070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-02-28 10:04:09.904081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-02-28 10:04:09.904314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-02-28 10:04:09.904521: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-02-28 10:04:09.904723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.53GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-02-28 10:04:09.904746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-02-28 10:04:09.904822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-02-28 10:04:09.904837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-02-28 10:04:09.904851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-02-28 10:04:09.904865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-02-28 10:04:09.904879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-02-28 10:04:09.904894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-02-28 10:04:09.904909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-02-28 10:04:09.905100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-02-28 10:04:09.905129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-02-28 10:04:09.905133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-02-28 10:04:09.905136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-02-28 10:04:09.905354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13188 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:17:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER_NAME = 'adaDelta'\n",
    "OPTIMIZER = adaDelta \n",
    "OPTIMIZER=tf.train.experimental.enable_mixed_precision_graph_rewrite(OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = tversky\n",
    "LOSS_NAME = 'tversky'\n",
    "modelToEvaluate =  r'/home/nkd/hbh/U_Net_GSW/saved_models/UNet/lakes_20210524-1616_AdaDelta_weightmap_tversky_01_512.h5'\n",
    "# modelToEvaluate =  r'/home/nkd/hbh/U_Net_GSW/saved_models/UNet/lakes_20240227-1502_AdaDelta_tversky_01_512.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nkd/hbh/evaluationreport/evaluation_per_pixel20240228-1004_01.csv\n"
     ]
    }
   ],
   "source": [
    "#File path for final report \n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "chf = input_image_channel + input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b),   chf, '')\n",
    "evaluation_report_path = model_path =  os.path.join(base_dir, 'evaluationreport') \n",
    "if not os.path.exists(evaluation_report_path):\n",
    "    os.makedirs(evaluation_report_path)\n",
    "evaluation_report_filename = os.path.join(evaluation_report_path,'evaluation_per_pixel{}_{}.csv'.format(timestr,chs))\n",
    "print(evaluation_report_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFrames(dataType):\n",
    "    frames=[]\n",
    "    print(dataType)\n",
    "    for i in range(1,7):\n",
    "        path_to_write=r'/home/nkd/hbh/normal/patchesReshape/{}/type{}'.format(dataType,i)\n",
    "        all_files = os.listdir(path_to_write)\n",
    "        all_files_GSW = [fn for fn in all_files if fn.startswith(GSW_fn) and fn.endswith(image_type)]#ndwi.png\n",
    "        print('type{} image number:{}'.format(i,len(all_files_GSW)))\n",
    "        for j, fn in enumerate(all_files_GSW):\n",
    "            GSW_img = rasterio.open(os.path.join(path_to_write, fn))\n",
    "            read_GSW_img = GSW_img.read()\n",
    "            comb_img = np.transpose(read_GSW_img, axes=(1,2,0)) #Channel at the end  ( , ,1) \n",
    "            annotation_im = Image.open(os.path.join(path_to_write, fn.replace(GSW_fn,annotation_fn)))\n",
    "            annotation = np.array(annotation_im)\n",
    "            f = FrameInfo(comb_img, annotation)\n",
    "            frames.append(f)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "type1 image number:36\n",
      "type2 image number:30\n",
      "type3 image number:42\n",
      "type4 image number:51\n",
      "type5 image number:2\n",
      "type6 image number:1\n",
      "test patchs number: 1453\n"
     ]
    }
   ],
   "source": [
    "frames=readFrames('test')\n",
    "test_patches = DataGenerator(input_image_channel,patch_size, frames, input_label_channel, augmenter = None).all_sequential_patches(step_size)\n",
    "print('test patchs number:',len(test_patches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nkd/hbh/U_Net_GSW/saved_models/UNet/lakes_20210524-1616_AdaDelta_weightmap_tversky_01_512.h5 /home/nkd/hbh/evaluationreport/evaluation_per_pixel20240228-1004_01.csv\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /home/nkd/hbh/U_Net_GSW/saved_models/UNet/lakes_20210524-1616_AdaDelta_weightmap_tversky_01_512.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_patch_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_patches[\u001b[38;5;241m0\u001b[39m])  \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m report\n\u001b[0;32m---> 16\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelToEvaluate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_report_filename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model_path, evaluation_report_filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model_path, evaluation_report_filename):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_path, evaluation_report_filename)\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtversky\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtversky\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdice_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdice_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mrecall\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIoU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mIoU\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mOPTIMIZER, loss\u001b[38;5;241m=\u001b[39mLOSS, metrics\u001b[38;5;241m=\u001b[39m[dice_loss, accuracy,recall,precision,IoU])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating model now!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/hbh_env/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py:211\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, six\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[0;32m--> 211\u001b[0m       \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(filepath, \u001b[38;5;28mcompile\u001b[39m, options)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to load model. Filepath is not an hdf5 file (or h5py is not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable) or SavedModel.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/hbh_env/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py:111\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (path_to_pbtxt, \u001b[38;5;28mstr\u001b[39m(e)))\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    112\u001b[0m                 (export_dir,\n\u001b[1;32m    113\u001b[0m                  constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT,\n\u001b[1;32m    114\u001b[0m                  constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB))\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /home/nkd/hbh/U_Net_GSW/saved_models/UNet/lakes_20210524-1616_AdaDelta_weightmap_tversky_01_512.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "#Evaluate model \n",
    "def evaluate_model(model_path, evaluation_report_filename):\n",
    "    print(model_path, evaluation_report_filename)\n",
    "    model = load_model(model_path, custom_objects={'tversky': tversky, 'dice_loss':dice_loss, 'accuracy':accuracy , 'recall':recall,'precision':precision,'IoU':IoU}, compile=False)\n",
    "\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_loss, accuracy,recall,precision,IoU])\n",
    "    \n",
    "    print('Evaluating model now!')\n",
    "    ev = model.evaluate(x=test_patches[0], y=test_patches[1],  verbose=1, use_multiprocessing=False)\n",
    "    report  = dict(zip(model.metrics_names, ev))\n",
    "    report['model_path'] =  model_path   \n",
    "    report['test_frame_dir']= base_dir   \n",
    "    report['total_patch_count']= len(test_patches[0])  \n",
    "    return report\n",
    "\n",
    "report = evaluate_model(modelToEvaluate, evaluation_report_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.08131864666938782, 'dice_loss': 0.08217889070510864, 'accuracy': 0.9915927052497864, 'recall': 0.9616610407829285, 'precision': 0.905194103717804, 'IoU': 0.8834644556045532, 'model_path': '/home/nkd/hbh/U_Net_GSW/saved_models/UNet/lakes_20240227-1502_AdaDelta_tversky_01_512.h5', 'test_frame_dir': '/home/nkd/hbh', 'total_patch_count': 1453}\n"
     ]
    }
   ],
   "source": [
    "print(report)\n",
    "\n",
    "# tdf = pd.DataFrame(report, index=[0])  \n",
    "# print(tdf.columns)\n",
    "# col_beginning = ['model_path','test_frame_dir', 'total_patch_count']\n",
    "\n",
    "# col_rest = [x for x in tdf.columns.tolist() if x not in col_beginning]\n",
    "# cols = col_beginning + col_rest\n",
    "# tdf = tdf[cols]\n",
    "# tdf.to_csv(evaluation_report_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbh_env",
   "language": "python",
   "name": "hbh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

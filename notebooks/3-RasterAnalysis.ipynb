{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Author: Ankit Kariryaa, University of Bremen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 20:45:36.347608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from rasterio import windows\n",
    "import fiona                  \n",
    "# I/O vector data (shape, geojson, ...)\n",
    "import geopandas as gps\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.geometry import mapping, shape\n",
    "import numpy as np               # numerical array manipulation\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import sys\n",
    "from core.UNet import UNet\n",
    "from core.o_losses import tversky, accuracy, dice_coef, dice_loss,IoU, recall,precision,F1_score\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.frame_info import FrameInfo\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.visualize import display_images\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 20:45:38.304568: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 20:45:38.306525: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-02-29 20:45:38.307446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-02-29 20:45:38.337061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.53GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-02-29 20:45:38.337095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-02-29 20:45:38.339590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-02-29 20:45:38.339691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-02-29 20:45:38.340559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-02-29 20:45:38.340818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-02-29 20:45:38.343032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-02-29 20:45:38.343562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-02-29 20:45:38.343700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-02-29 20:45:38.344014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-02-29 20:45:38.344043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-02-29 20:45:38.764179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-02-29 20:45:38.764223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-02-29 20:45:38.764229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-02-29 20:45:38.764841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 31584 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:17:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto(\n",
    "    #device_count={\"CPU\": 64},\n",
    "    allow_soft_placement=True, \n",
    "    log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.trained_model_path: /home/nkd/hbh/U_Net_GSW/saved_models/UNet/lakes_20240228-1124_AdaDelta_tversky_01_512.h5\n"
     ]
    }
   ],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/RasterAnalysis.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    " \n",
    "from config import RasterAnalysis\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import RasterAnalysis\n",
    "config = RasterAnalysis.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3608766/2285262299.py:3: enable_mixed_precision_graph_rewrite (from tensorflow.python.training.experimental.mixed_precision) is deprecated and will be removed after 2020-11-30.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision. There is a guide at https://www.tensorflow.org/guide/mixed_precision. Alternatively, `tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite` can be used, but this is not recommended for TF2 code.\n",
      "WARNING:tensorflow:You already have existing Sessions that do not use mixed precision. enable_mixed_precision_graph_rewrite() will not affect these Sessions.\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA RTX A6000, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 20:45:38.842147: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-02-29 20:45:38.842757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.53GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-02-29 20:45:38.842814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-02-29 20:45:38.842912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-02-29 20:45:38.842961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-02-29 20:45:38.842993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-02-29 20:45:38.843025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-02-29 20:45:38.843057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-02-29 20:45:38.843089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-02-29 20:45:38.843128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-02-29 20:45:38.843818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-02-29 20:45:38.844193: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-02-29 20:45:38.844584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.53GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-02-29 20:45:38.844626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-02-29 20:45:38.844717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-02-29 20:45:38.844761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-02-29 20:45:38.844803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-02-29 20:45:38.844845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-02-29 20:45:38.844887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-02-29 20:45:38.844928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-02-29 20:45:38.844971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-02-29 20:45:38.845464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-02-29 20:45:38.845509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-02-29 20:45:38.845519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-02-29 20:45:38.845529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-02-29 20:45:38.846083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 31584 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:17:00.0, compute capability: 8.6)\n",
      "2024-02-29 20:45:38.865943: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained model \n",
    "OPTIMIZER = adaDelta\n",
    "OPTIMIZER=tf.train.experimental.enable_mixed_precision_graph_rewrite(OPTIMIZER)\n",
    "model = load_model(config.trained_model_path, custom_objects={'dice_loss':dice_loss, 'accuracy':accuracy, 'IoU': IoU,'precision':precision, 'recall':recall,'F1_score':F1_score}, compile=False)\n",
    "model.compile(optimizer=OPTIMIZER, loss=tversky, metrics=[dice_loss, accuracy,IoU, recall, precision,F1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to add results of a patch   to    the total results of a larger area. \n",
    "#The operator could be min (useful if there are too many false positives), max (useful for tackle false negatives)\n",
    "def addTOResult(res, prediction, row, col, he, wi, operator = 'MAX'):\n",
    "    currValue = res[row:row+he, col:col+wi]\n",
    "    newPredictions = prediction[:he, :wi]\n",
    "# IMPORTANT: MIN can't be used as long as the mask is initialed with 0!!!!! \n",
    "#If you want to use MIN initial the mask with -1 and handle the case of default value(-1) separately.\n",
    "    if operator == 'MIN': # Takes the min of current prediction and new prediction for each pixel  \n",
    "        currValue [currValue == -1] = 1 #Replace -1 with 1 in case of MIN  \n",
    "        resultant = np.minimum(currValue, newPredictions)\n",
    "    elif operator == 'MAX':\n",
    "        resultant = np.maximum(currValue, newPredictions)\n",
    "    else: #operator == 'REPLACE':\n",
    "        resultant = newPredictions  \n",
    "# Alternative approach; Lets assume that quality of prediction is better in the centre of the image than on the edges \n",
    "# We use numbers from 1-5 to denote the quality, where 5 is the best and 1 is the worst.\n",
    "# In that case, the best result would be to take into quality of prediction based upon position in account  \n",
    "# So for merge with stride of 0.5, for eg. [12345432100000] AND [00000123454321], should be [1234543454321] instead of [1234543214321] that you will currently get. \n",
    "# However, in case the values are strecthed before hand this problem will be minimized \n",
    "    res[row:row+he, col:col+wi] =  resultant\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that actually makes the predictions\n",
    "def predict_using_model(model, batch, batch_pos, mask, operator):\n",
    "    tm = np.stack(batch, axis = 0)\n",
    "    prediction = model.predict(tm)\n",
    "    for i in range(len(batch_pos)): \n",
    "        (col, row, wi, he) = batch_pos[i]\n",
    "        p = np.squeeze(prediction[i], axis = -1)\n",
    "        # Instead of replacing the current values with new values, use the user specified operator (MIN,MAX,REPLACE)\n",
    "        mask = addTOResult(mask, p, row, col, he, wi, operator)  \n",
    "    return mask\n",
    "    \n",
    "def detect_tree(GSW_img, width=512, height=512, stride = 256):\n",
    "    nols, nrows = GSW_img.meta['width'], GSW_img.meta['height']\n",
    "    meta = GSW_img.meta.copy() \n",
    "    if 'float' not in meta['dtype']: #The prediction is a float so we keep it as float to be consistent with the prediction. \n",
    "        meta['dtype'] = np.float32\n",
    "    offsets = product(range(0, nols, stride), range(0, nrows, stride))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    print('the size of current GSW_img',nrows, nols) \n",
    "\n",
    "    mask = np.zeros((nrows, nols), dtype=meta['dtype'])\n",
    "\n",
    "#     mask = mask -1   # Note: The initial mask is initialized with -1 instead of zero   to handle the MIN case (see addToResult)\n",
    "    batch = []\n",
    "    batch_pos = [ ]\n",
    "    for col_off, row_off in  tqdm(offsets):\n",
    "        window =windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, GSW_img.transform) \n",
    "        patch = np.zeros((height, width, 1))#Add zero padding in case of corner images\n",
    "        GSW_sm = GSW_img.read(window=window)\n",
    "        temp_im = np.stack(GSW_sm, axis = -1)\n",
    "        patch[:window.height, :window.width] = temp_im   \n",
    "        batch.append(patch)\n",
    "        batch_pos.append((window.col_off, window.row_off, window.width, window.height))\n",
    "        if (len(batch) == config.BATCH_SIZE):\n",
    "            mask = predict_using_model(model, batch, batch_pos, mask, 'MAX')\n",
    "            batch = []\n",
    "            batch_pos = []\n",
    "            \n",
    "    # To handle the edge of images as the image size may not be divisible by n complete batches and few frames on the edge may be left.\n",
    "    if batch:\n",
    "        mask = predict_using_model(model, batch, batch_pos, mask, 'MAX')\n",
    "        batch = []\n",
    "        batch_pos = []\n",
    "\n",
    "    return(mask, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeMaskToDisk(detected_mask, detected_meta, wp, write_as_type = 'uint8', th = 0.5, create_countors = False):\n",
    "    # Convert to correct required before writing\n",
    "    if 'float' in str(detected_meta['dtype']) and 'int' in write_as_type:\n",
    "        print(f'Converting prediction from {detected_meta[\"dtype\"]} to {write_as_type}, using threshold of {th}')#float32 to uint8\n",
    "        detected_mask[detected_mask<th]=0\n",
    "        detected_mask[detected_mask>=th]=1\n",
    "        detected_mask = detected_mask.astype(write_as_type)#'uint8'\n",
    "        detected_meta['dtype'] =  write_as_type\n",
    "    \n",
    "    # compress tif\n",
    "    detected_meta.update({\"compress\": 'lzw'})\n",
    "    \n",
    "    with rasterio.open(wp, 'w', **detected_meta) as outds:\n",
    "        outds.write(detected_mask, 1)\n",
    "    if create_countors:\n",
    "        wp = wp.replace(image_type, output_shapefile_type)\n",
    "        create_contours_shapefile(detected_mask, detected_meta, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict trees in the all the files in the input image dir \n",
    "# Depending upon the available RAM, images may not to be split before running this cell.\n",
    "# Use the Auxiliary-2-SplitRasterToAnalyse if the images are too big to be analysed in memory.\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(config.input_image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(config.input_image_type) and file.startswith(config.GSW_fn_st):\n",
    "             all_files.append((os.path.join(root, file), file))\n",
    "# print(all_files)\n",
    "\n",
    "for fullPath, filename in all_files:\n",
    "    outputFile = os.path.join(config.output_dir, filename.replace(config.GSW_fn_st, config.output_prefix) )\n",
    "    if not os.path.isfile(outputFile) or config.overwrite_analysed_files: \n",
    "        with rasterio.open(fullPath) as GSW:\n",
    "            print(fullPath)\n",
    "            detectedMask, detectedMeta = detect_tree(GSW, width = config.WIDTH, height = config.HEIGHT, stride = config.STRIDE)\n",
    "            # WIDTH and HEIGHT should be the same and in this case Stride is 50 % width\n",
    "            #Write the mask to file\n",
    "            writeMaskToDisk(detectedMask, detectedMeta, outputFile, write_as_type = config.output_dtype, th = 0.5, create_countors = False)            \n",
    "\n",
    "    else:\n",
    "        print('File already analysed!', fullPath)\n",
    "        \n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display extracted image\n",
    "# sampleImage = '_80E_80Nv1_1_2019.tif'\n",
    "# fn = os.path.join(config.output_dir, config.output_prefix + sampleImage )\n",
    "# predicted_img = rasterio.open(fn)\n",
    "# p = predicted_img.read()\n",
    "# np.unique(p, return_counts=True)\n",
    "# plt.imshow(p[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbh_env",
   "language": "python",
   "name": "hbh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

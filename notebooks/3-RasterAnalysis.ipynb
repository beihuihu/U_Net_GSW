{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Author: Ankit Kariryaa, University of Bremen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0-rc3\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from rasterio import windows\n",
    "import fiona                  \n",
    "# I/O vector data (shape, geojson, ...)\n",
    "import geopandas as gps\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.geometry import mapping, shape\n",
    "import numpy as np               # numerical array manipulation\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import sys\n",
    "from core.UNet import UNet\n",
    "from core.losses import tversky, accuracy, dice_coef, dice_loss,IoU, recall,precision\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.frame_info import FrameInfo, image_normalize\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.visualize import display_images\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto(\n",
    "    #device_count={\"CPU\": 64},\n",
    "    allow_soft_placement=True, \n",
    "    log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.trained_model_path: G:\\U-Net\\U-Net\\saved_models\\UNet\\lakes_20230622-0246_AdaDelta_tversky_01_512.h5\n"
     ]
    }
   ],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/RasterAnalysis.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    " \n",
    "from config import RasterAnalysis\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import RasterAnalysis\n",
    "config = RasterAnalysis.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20432\\2000518957.py:3: enable_mixed_precision_graph_rewrite (from tensorflow.python.training.experimental.mixed_precision) is deprecated and will be removed after 2020-11-30.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision. There is a guide at https://www.tensorflow.org/guide/mixed_precision. Alternatively, `tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite` can be used, but this is not recommended for TF2 code.\n",
      "WARNING:tensorflow:You already have existing Sessions that do not use mixed precision. enable_mixed_precision_graph_rewrite() will not affect these Sessions.\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mIoU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m OPTIMIZER \u001b[38;5;241m=\u001b[39m adaDelta\n\u001b[0;32m      3\u001b[0m OPTIMIZER\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39menable_mixed_precision_graph_rewrite(OPTIMIZER)\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(config\u001b[38;5;241m.\u001b[39mtrained_model_path, custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtversky\u001b[39m\u001b[38;5;124m'\u001b[39m: tversky, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdice_coef\u001b[39m\u001b[38;5;124m'\u001b[39m: dice_coef, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdice_loss\u001b[39m\u001b[38;5;124m'\u001b[39m:dice_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m:accuracy, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmIoU\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mmIoU\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecificity\u001b[39m\u001b[38;5;124m'\u001b[39m:specificity, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensitivity\u001b[39m\u001b[38;5;124m'\u001b[39m:sensitivity}, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mOPTIMIZER, loss\u001b[38;5;241m=\u001b[39mtversky, metrics\u001b[38;5;241m=\u001b[39m[dice_coef, dice_loss, accuracy,mIoU, specificity, sensitivity])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mIoU' is not defined"
     ]
    }
   ],
   "source": [
    "# Load a pretrained model \n",
    "OPTIMIZER = adaDelta\n",
    "OPTIMIZER=tf.train.experimental.enable_mixed_precision_graph_rewrite(OPTIMIZER)\n",
    "model = load_model(config.trained_model_path, custom_objects={'tversky': tversky, 'dice_coef': dice_coef, 'dice_loss':dice_loss, 'accuracy':accuracy, 'IoU': IoU,'specificity':specificity, 'sensitivity':sensitivity}, compile=False)\n",
    "model.compile(optimizer=OPTIMIZER, loss=tversky, metrics=[dice_coef, dice_loss, accuracy,mIoU, specificity, sensitivity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to add results of a patch   to    the total results of a larger area. \n",
    "#The operator could be min (useful if there are too many false positives), max (useful for tackle false negatives)\n",
    "def addTOResult(res, prediction, row, col, he, wi, operator = 'MAX'):\n",
    "    currValue = res[row:row+he, col:col+wi]\n",
    "    newPredictions = prediction[:he, :wi]\n",
    "# IMPORTANT: MIN can't be used as long as the mask is initialed with 0!!!!! \n",
    "#If you want to use MIN initial the mask with -1 and handle the case of default value(-1) separately.\n",
    "    if operator == 'MIN': # Takes the min of current prediction and new prediction for each pixel  \n",
    "        currValue [currValue == -1] = 1 #Replace -1 with 1 in case of MIN  \n",
    "        resultant = np.minimum(currValue, newPredictions)\n",
    "    elif operator == 'MAX':\n",
    "        resultant = np.maximum(currValue, newPredictions)\n",
    "    else: #operator == 'REPLACE':\n",
    "        resultant = newPredictions  \n",
    "# Alternative approach; Lets assume that quality of prediction is better in the centre of the image than on the edges \n",
    "# We use numbers from 1-5 to denote the quality, where 5 is the best and 1 is the worst.\n",
    "# In that case, the best result would be to take into quality of prediction based upon position in account  \n",
    "# So for merge with stride of 0.5, for eg. [12345432100000] AND [00000123454321], should be [1234543454321] instead of [1234543214321] that you will currently get. \n",
    "# However, in case the values are strecthed before hand this problem will be minimized \n",
    "    res[row:row+he, col:col+wi] =  resultant\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that actually makes the predictions\n",
    "def predict_using_model(model, batch, batch_pos, mask, operator):\n",
    "    tm = np.stack(batch, axis = 0)\n",
    "    prediction = model.predict(tm)\n",
    "    for i in range(len(batch_pos)): \n",
    "        (col, row, wi, he) = batch_pos[i]\n",
    "        p = np.squeeze(prediction[i], axis = -1)\n",
    "        # Instead of replacing the current values with new values, use the user specified operator (MIN,MAX,REPLACE)\n",
    "        mask = addTOResult(mask, p, row, col, he, wi, operator)  \n",
    "    return mask\n",
    "    \n",
    "def detect_tree(GSW_img, width=512, height=512, stride = 256, normalize=True):\n",
    "    nols, nrows = GSW_img.meta['width'], GSW_img.meta['height']\n",
    "    meta = GSW_img.meta.copy() \n",
    "    if 'float' not in meta['dtype']: #The prediction is a float so we keep it as float to be consistent with the prediction. \n",
    "        meta['dtype'] = np.float32\n",
    "    offsets = product(range(0, nols, stride), range(0, nrows, stride))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    print('the size of current GSW_img',nrows, nols) \n",
    "\n",
    "    mask = np.zeros((nrows, nols), dtype=meta['dtype'])\n",
    "\n",
    "#     mask = mask -1   # Note: The initial mask is initialized with -1 instead of zero   to handle the MIN case (see addToResult)\n",
    "    batch = []\n",
    "    batch_pos = [ ]\n",
    "    for col_off, row_off in  tqdm(offsets):\n",
    "        window =windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, GSW_img.transform) \n",
    "        patch = np.zeros((height, width, 1))#Add zero padding in case of corner images\n",
    "        GSW_sm = GSW_img.read(window=window)\n",
    "        temp_im = np.stack(GSW_sm, axis = -1)\n",
    "        \n",
    "        if normalize:\n",
    "            temp_im = image_normalize(temp_im, axis=(0,1)) #Normalize the image along the width and height i.e. independently per channel\n",
    "            \n",
    "        patch[:window.height, :window.width] = temp_im   \n",
    "        batch.append(patch)\n",
    "        batch_pos.append((window.col_off, window.row_off, window.width, window.height))\n",
    "        if (len(batch) == config.BATCH_SIZE):\n",
    "            mask = predict_using_model(model, batch, batch_pos, mask, 'MAX')\n",
    "            batch = []\n",
    "            batch_pos = []\n",
    "            \n",
    "    # To handle the edge of images as the image size may not be divisible by n complete batches and few frames on the edge may be left.\n",
    "    if batch:\n",
    "        mask = predict_using_model(model, batch, batch_pos, mask, 'MAX')\n",
    "        batch = []\n",
    "        batch_pos = []\n",
    "\n",
    "    return(mask, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {'id': 'str', 'area': 'float:15.2',},\n",
    "    }\n",
    "\n",
    "\n",
    "def drawPolygons(polygons, shape):\n",
    "    mask = np.zeros(shape, dtype=np.uint8)  \n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    for polygon in polygons:\n",
    "        xy = [(point[1], point[0]) for point in polygon]\n",
    "        draw.polygon(xy=xy, outline=255, fill=255)\n",
    "    mask = np.array(mask)#, dtype=bool)  #mask \n",
    "    return(mask)\n",
    "\n",
    "\n",
    "def transformToXY(polygons, transform):\n",
    "    tp = []\n",
    "    for polygon in polygons:\n",
    "        rows, cols = zip(*polygon)\n",
    "        x,y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tp.append(list(zip(x,y)))\n",
    "    return (tp)\n",
    "\n",
    "\n",
    "def createShapefileObject(polygons, meta, wfile):\n",
    "    with fiona.open(wfile, 'w', crs=meta.get('crs').to_dict(), driver='ESRI Shapefile', schema=schema) as sink:\n",
    "        for idx, mp in enumerate(polygons):\n",
    "            try:\n",
    "#                 poly = Polygon(poly)\n",
    "    #             assert mp.is_valid\n",
    "    #             assert mp.geom_type == 'Polygon'\n",
    "                sink.write({\n",
    "                    'geometry': mapping(mp),\n",
    "                    'properties': {'id': str(idx), 'area': mp.area},\n",
    "                })\n",
    "            except:\n",
    "                print(\"An exception occurred in createShapefileObject; Polygon must have more than 2 points\")\n",
    "#                 print(mp)\n",
    "\n",
    "# Generate a mask with polygons\n",
    "def transformContoursToXY(contours, transform = None):\n",
    "    tp = []\n",
    "    for cnt in contours:\n",
    "        pl = cnt[:, 0, :]\n",
    "        cols, rows = zip(*pl)\n",
    "        x,y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tl = [list(i) for i in zip(x, y)]\n",
    "        tp.append(tl)\n",
    "    return (tp)\n",
    "\n",
    "def mask_to_polygons(maskF, transform):\n",
    "    # first, find contours with cv2: it's much faster than shapely   \n",
    "    th = 0.5\n",
    "#     th = 0.45\n",
    "    mask = maskF.copy()\n",
    "    mask[mask < th] = 0\n",
    "    mask[mask >= th] = 1\n",
    "    mask = ((mask) * 255).astype(np.uint8)\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    #Convert contours from image coordinate to xy coordinate    \n",
    "    contours = transformContoursToXY(contours, transform) \n",
    "    if not contours: #TODO: Raise an error maybe\n",
    "        print('Warning: No contours/polygons detected!!')\n",
    "        return [Polygon()]\n",
    "    \n",
    "    # now messy stuff to associate parent and child contours\n",
    "    cnt_children = defaultdict(list)\n",
    "    child_contours = set()\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
    "        if parent_idx != -1:\n",
    "            child_contours.add(idx)\n",
    "            cnt_children[parent_idx].append(contours[idx])\n",
    "\n",
    "    # create actual polygons filtering by area (removes artifacts) \n",
    "    all_polygons = []\n",
    "    \n",
    "    for idx, cnt in enumerate(contours):\n",
    "        if idx not in child_contours: #and cv2.contourArea(cnt) >= min_area: #Do we need to check for min_area??\n",
    "            try:\n",
    "                poly = Polygon(\n",
    "                    shell=cnt,\n",
    "                    holes=[c for c in cnt_children.get(idx, [])])\n",
    "                           #if cv2.contourArea(c) >= min_area]) #Do we need to check for min_area??\n",
    "                all_polygons.append(poly)\n",
    "            except:\n",
    "                pass\n",
    "#                 print(\"An exception occurred in createShapefileObject; Polygon must have more than 2 points\")\n",
    "    print(len(all_polygons))\n",
    "    return(all_polygons)\n",
    "\n",
    "\n",
    "def create_contours_shapefile(mask, meta, out_fn):\n",
    "    res = mask_to_polygons(mask, meta['transform'])\n",
    "#     res = transformToXY(contours, meta['transform'])\n",
    "    createShapefileObject(res, meta, out_fn)\n",
    "\n",
    "\n",
    "def writeMaskToDisk(detected_mask, detected_meta, wp, write_as_type = 'uint8', th = 0.5, create_countors = False):\n",
    "    # Convert to correct required before writing\n",
    "    if 'float' in str(detected_meta['dtype']) and 'int' in write_as_type:\n",
    "        print(f'Converting prediction from {detected_meta[\"dtype\"]} to {write_as_type}, using threshold of {th}')#float32 to uint8\n",
    "        detected_mask[detected_mask<th]=0\n",
    "        detected_mask[detected_mask>=th]=1\n",
    "        detected_mask = detected_mask.astype(write_as_type)#'uint8'\n",
    "        detected_meta['dtype'] =  write_as_type\n",
    "    \n",
    "    # compress tif\n",
    "    detected_meta.update({\"compress\": 'lzw'})\n",
    "    \n",
    "    with rasterio.open(wp, 'w', **detected_meta) as outds:\n",
    "        outds.write(detected_mask, 1)\n",
    "    if create_countors:\n",
    "        wp = wp.replace(image_type, output_shapefile_type)\n",
    "        create_contours_shapefile(detected_mask, detected_meta, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict trees in the all the files in the input image dir \n",
    "# Depending upon the available RAM, images may not to be split before running this cell.\n",
    "# Use the Auxiliary-2-SplitRasterToAnalyse if the images are too big to be analysed in memory.\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(config.input_image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(config.input_image_type) and file.startswith(config.GSW_fn_st):\n",
    "             all_files.append((os.path.join(root, file), file))\n",
    "# print(all_files)\n",
    "\n",
    "for fullPath, filename in all_files:\n",
    "    outputFile = os.path.join(config.output_dir, filename.replace(config.GSW_fn_st, config.output_prefix) )\n",
    "    if not os.path.isfile(outputFile) or config.overwrite_analysed_files: \n",
    "        with rasterio.open(fullPath) as GSW:\n",
    "            print(fullPath)\n",
    "            detectedMask, detectedMeta = detect_tree(GSW, width = config.WIDTH, height = config.HEIGHT, stride = config.STRIDE)\n",
    "            # WIDTH and HEIGHT should be the same and in this case Stride is 50 % width\n",
    "            #Write the mask to file\n",
    "            writeMaskToDisk(detectedMask, detectedMeta, outputFile, write_as_type = config.output_dtype, th = 0.5, create_countors = False)            \n",
    "\n",
    "    else:\n",
    "        print('File already analysed!', fullPath)\n",
    "        \n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display extracted image\n",
    "# sampleImage = '_80E_80Nv1_1_2019.tif'\n",
    "# fn = os.path.join(config.output_dir, config.output_prefix + sampleImage )\n",
    "# predicted_img = rasterio.open(fn)\n",
    "# p = predicted_img.read()\n",
    "# np.unique(p, return_counts=True)\n",
    "# plt.imshow(p[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
